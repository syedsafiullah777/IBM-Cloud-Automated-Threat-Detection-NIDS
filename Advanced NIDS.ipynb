{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Threat Detection using Machine Learning\n",
    "\n",
    "## Project Overview\n",
    "This project demonstrates a complete machine learning workflow for building a robust Network Intrusion Detection System (NIDS). The system is designed to classify network traffic as either normal or one of several specific cyberattack categories (e.g., DoS, Probe, R2L, U2R). This notebook is prepared for public sharing on GitHub and has had all personal credentials removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -U scikit-learn pandas numpy matplotlib seaborn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports for preprocessing, modeling, and evaluation\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Local Datasets\n",
    "\n",
    "This cell loads the data from local CSV files. To run this notebook, ensure `Train_data.csv` and `Test_data.csv` are in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train_raw = pd.read_csv('Train_data.csv')\n",
    "    df_test_raw = pd.read_csv('Test_data.csv')\n",
    "    print(\"Training and Test data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'Train_data.csv' and 'Test_data.csv' are in the same folder as the notebook.\")\n",
    "\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data Info:\")\n",
    "df_train_raw.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values in training data: {df_train_raw.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Multiclass Labels\n",
    "For demonstration, we simulate multiclass labels based on the binary 'anomaly' class to showcase the model's classification capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'attack_category' column\n",
    "attack_map = {0: 'Normal', 1: 'DoS', 2: 'Probe', 3: 'R2L', 4: 'U2R'}\n",
    "anomaly_indices = df_train_raw[df_train_raw['class'] == 'anomaly'].index\n",
    "\n",
    "# Simulate the multiclass labels for anomalies\n",
    "np.random.seed(42) # for reproducibility\n",
    "simulated_attacks = np.random.choice([1, 2, 3, 4], size=len(anomaly_indices), p=[0.75, 0.15, 0.08, 0.02])\n",
    "\n",
    "df_train_raw['attack_category'] = 'Normal'\n",
    "df_train_raw.loc[anomaly_indices, 'attack_category'] = [attack_map[x] for x in simulated_attacks]\n",
    "\n",
    "# Visualize the new multiclass distribution\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.countplot(y='attack_category', data=df_train_raw, order=df_train_raw['attack_category'].value_counts().index)\n",
    "plt.title('Distribution of Network Traffic by Attack Category')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Attack Category')\n",
    "plt.show()\n",
    "\n",
    "# Drop the original binary 'class' column\n",
    "df_train = df_train_raw.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df_train.drop('attack_category', axis=1)\n",
    "y = df_train['attack_category']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Create the preprocessing pipelines\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer to apply different transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the model pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the Random Forest model...\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "print(\"\\n--- Model Evaluation Report ---\")\n",
    "y_pred = model_pipeline.predict(X_val)\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained model\n",
    "try:\n",
    "    ohe_feature_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "    all_feature_names = np.concatenate([numerical_features, ohe_feature_names])\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': all_feature_names,\n",
    "        'Importance': model_pipeline.named_steps['classifier'].feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot the top 20 most important features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Most Important Features for Intrusion Detection')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot feature importances: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}